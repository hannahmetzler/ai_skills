---
titel: "Introduction Draft in English"
subtitle: "Copy from the WISIA workshop with small updates"
author: "Hannah Metzler"
date: "October 29 2024"
format: 
  revealjs: 
    transition: "slide"
    ## Defines the theme of the presentation, both version and style
    theme: [default, custom.scss]
    # incremental slides point by point
    incremental: false
    aspect-ratio: 16:9
    slide-number: true
# title-slide-attributes:
# data-background-image: images/
# data-background-size: cover
# data-background-opacity: "0.5"
#editor
editor: source
---

# Introduction

## What is an LLM, actually?

-   Large Language Models: Neural networks = Deep Learning models trained on text
-   Advanced Language models that process huge amounts of text
-   Trained with huge amounts of text data from the Internet (Wikipedia, social media, online media, books, literature, videos, films, YouTube, podcasts...)
-   Turn it into statistical word and sentence predictions
-   Can provide detailed and context-rich answers

## Neural networks [Maybe incluce this slide Konstantin?]

-   Multiple layers of "neurons"
-   Deep learning
-   Linear regressions calculate "weights" for the connections

::::: columns
::: {.column width="47%"}
-   Input layer: Quantitative representation of sentence
-   Output layer: One-hot encoding
:::

::: {.column width="47%"}
```{r, echo=FALSE}
knitr::include_graphics("images/neuralnet.svg")
```
:::
:::::

::: notes
One hot encoding: output has as many units as words, we predict the one with the maximum value, probabilities of words Input: one-hot times embedding, everything but the mask
:::

## How are words represented numerically?

::::: columns
::: {.column width="40%"}
-   Vector embeddings <br> = word embeddings

```{r}
knitr::include_graphics("images/wordembeddings.svg")
```
:::

::: {.column width="56%"}
-   LLMs: contextual word embeddings
-   Kontext (vor und nach dem Wort) wird mit repräsentiert
-   [Beispiel](https://www.tiktok.com/@whats_ai/video/7247609946672565510) "Apple": Mac oder Frucht?

```{r, fig.align="center", out.width=250}
knitr::include_graphics("images/apple_context.png")
```
:::
:::::

## How are LLMs trained? - to do: update

All Transformer models (a model architecture for efficient computing):

-   BERT specific, to update: **Masked word prediction**
    -   “New **\[MASK\]** is a city”
-   **Next sentence prediction**
    -   "Today is a beautiful sunny day, and I decided to go for a long walk in the park. Suddenly, the quadratic equation was solved."\
    -   TRUE/FALSE als Feedback
    


## Current top models - To do: update

-   **ChatGPT-4o** (Open AI)
-   **Claude Sonnet 3.5** (Anthropic)
-   **Bard (Gemini)** (Google)

## Strengths of different models - update

-   [**ChatGPT-4**](https://chat.openai.com/) (Open AI): multimodal interactions, 8.000 tokens (more with API)
-   [**Claude 3.5 Sonnet**](https://claude.ai/) (Anthropic): Writing style, longer context window (200.000 tokens)
-   [**Gemini**](https://gemini.google.com/app) (Google): ??? (Search capability and database, integration with Google services), 100.000 tokens

Source: [Chatbot Arena](https://chat.lmsys.org/) - Leaderbord


::: notes
multimodal interactions with ChatGPT described on next slide
:::


## Multimodal ChatGPT interactions

**(Some also work with Claude)**

- File Uploads (& Claude)
- Browse
- Discovering and using GPTs
- Upload & analyze images
- Create images with DALL-E
- Audio: Talking/Listening
- Data analysis (& Claude)
- Execute code

## Slide on Chatbot Arena?



## Different ChatGPT versions

- ChatGPT4: more resource intensive = expensive
- ChatGPT4o = optimized to be faster and cheaper
- ChatGPT-4o mini: every day tasks
- Only via API or special access plans:
  - ChatGPT-4 Turbo: long context window (128.000 tokens)
  - o1-preview: advanced reasoning
  - ChatGPT-3.5: less resource intense
  
::: footer
[ChatGPT blog on models](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4-gpt-4-turbo-gpt-4o-and-gpt-4o-mini)

::: 






## Access to models

| model      | free access                       | costs /month |
|------------|-----------------------------------|--------------|
| ChatGPT    | GPT-4o mini, GPT4-o limited, limits for multimodal   | 24€          |
| Claude   | 200 tokens/day                    | ca \$20      |
| Gemini      | 1 month trial of paid version, 2500 tokens/day                   | 21.99€     |
| Perplexity | 3 requests/day, 1000 tokens/month | \$17-20      |
| Elicit     | 1000 tokens/month                 | \$10-12      |

::: notes
To Do: update requests/limits, maybe just write "limited" under free access rather than the details?
:::


## Discussion 

- In groups of 3 (10 minutes): 
  - Which problems do you encounter when using LLMs? 
  - What works well?
- 5 minutes for sharing most important points with the whole group

