<!DOCTYPE html>
<html lang="en"><head>
<script src="writing_files/libs/clipboard/clipboard.min.js"></script>
<script src="writing_files/libs/quarto-html/tabby.min.js"></script>
<script src="writing_files/libs/quarto-html/popper.min.js"></script>
<script src="writing_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="writing_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="writing_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="writing_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="writing_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.57">

  <meta name="author" content="Konstantin Hebenstreit">
  <meta name="dcterms.date" content="2024-10-29">
  <title>Using Chatbots for Writing</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="writing_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="writing_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="writing_files/libs/revealjs/dist/theme/quarto.css">
  <link href="writing_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="writing_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="writing_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="writing_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Using Chatbots for Writing</h1>
  <p class="subtitle">Mastering AI Chatbots: Optimizing Research through Effective Use</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Konstantin Hebenstreit 
</div>
</div>
</div>

  <p class="date">2024-10-29</p>
</section>
<section id="writing-sections-of-papers" class="slide level2">
<h2>Writing sections of papers</h2>
<h3 id="test-how-good-is-the-ai-in-writing-a-discussion">Test how good is the AI in writing a discussion</h3>
<p>Try out: (Re-)Writing the discussion of a given paper</p>
<ol type="1">
<li>Choose a paper you know very well, best would be one of your own.</li>
<li>Give the paper without the discussion to the model “o1-preview”</li>
<li>Let it write the discussion on it’s own</li>
<li>Check how it is doing</li>
</ol>
</section>
<section id="my-example" class="slide level2">
<h2>My example</h2>
<h3 id="paper-about-generalization-of-prompting-strategies">Paper about generalization of prompting strategies</h3>

<img data-src="images/peerj_screenshot.png" class="r-stretch"><div class="footer">
<p>Hebenstreit et al.&nbsp;<a href="https://peerj.com/articles/cs-1999/#">2024</a></p>
</div>
<aside class="notes">
<p>In the last step of creating this session I was rereading the prompting guidlines of o1 and also copying the text with tables from the website, which made the formatting better.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="ai-generated-discussion" class="slide level2 smaller" style="font-size: 0.4em;">
<h2>AI generated discussion:</h2>
<p>In this study, we conducted a comprehensive comparison of zero-shot chain-of-thought (CoT) reasoning strategies across multiple large language models (LLMs) and diverse datasets. Our findings highlight that while the effectiveness of specific reasoning strategies can vary depending on the model and dataset, overall gains from CoT reasoning remain robust. Notably, GPT-4 demonstrated the most significant improvements when applying advanced reasoning prompts, particularly the “Zhou” prompt discovered through automated prompt engineering (Zhou et al., 2023b).</p>
<p>Effectiveness of Reasoning Strategies</p>
<p>Our results indicate that employing explicit reasoning prompts generally outperforms direct prompting without any specific CoT trigger. The “Zhou” prompt—“Let’s work this out in a step by step way to be sure we have the right answer.”—consistently yielded the highest performance across models, especially with GPT-4. This aligns with previous research suggesting that guiding models to think step by step enhances their ability to solve complex problems (Wei et al., 2022; Kojima et al., 2022).</p>
<p>Interestingly, while GPT-4 benefited significantly from externalized reasoning prompts, models like Flan-T5-xxl did not exhibit the same level of improvement. For Flan-T5-xxl, direct prompting remained among the optimal methods. This suggests that the efficacy of CoT reasoning strategies may be model-dependent, possibly due to differences in training data, architecture, or inherent reasoning capabilities.</p>
<p>Model Performance Across Datasets</p>
<p>The performance of models varied notably across different datasets. GPT-4 and GPT-3.5-turbo achieved the highest scores overall, particularly excelling in datasets like WorldTree v2 and CommonsenseQA. These datasets, which require general knowledge and logical reasoning, appear to be well-suited for advanced LLMs. The superior performance on WorldTree v2 suggests that better models find this dataset increasingly easier, potentially due to their enhanced ability to process and reason with scientific facts.</p>
<p>Conversely, StrategyQA presented challenges, with models showing lower performance due to the dataset’s ambiguous items. This highlights the impact of question clarity on model performance and suggests that even advanced models struggle with poorly defined problems.</p>
<p>The medical datasets, MedQA and MedMCQA, were the most difficult for all models. Only GPT-4 and GPT-3.5-turbo displayed acceptable performance levels, underscoring the complexity of medical knowledge and the limitations of LLMs without specialized training in this domain. The low performance of models like Flan-T5-xxl on MedQA (Krippendorff’s alpha close to chance) emphasizes the need for domain-specific fine-tuning to improve accuracy in specialized fields.</p>
<p>Impact of Data Contamination</p>
<p>(…)</p>
<aside class="notes">
<p>People often tell me that they are frustrated because they have to read all of that text the AI is providing.</p>
<p>We need to find a method that is easy for us. Easy to test if the Chatbot is doing what we want.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="read-o1-prompting-tips" class="slide level2">
<h2>Read o1 prompting tips</h2>
<p>Remember that for <a href="https://platform.openai.com/docs/guides/reasoning/advice-on-prompting">prompting o1</a>: keep it simple, avoid chain-of-thought and use delimeters for clarity</p>
<p><strong>New Prompt:</strong> Please write a concise and scientifically rigorous discussion section for my paper, maintaining consistency with my writing style demonstrated below. Respond in plain text formatted as markdown.</p>
<p>Here is the finished paper up to the discussion section:</p>
<p>’’’</p>
<p>[Insert your paper’s text up to the discussion section.]</p>
<p>’’’</p>
</section>
<section id="output-with-better-prompt" class="slide level2 smaller" style="font-size: 0.4em;">
<h2>Output with better prompt</h2>
<p>This study systematically evaluated ten zero-shot chain-of-thought (CoT) prompting strategies across six instruction-tuned language models on six diverse question-answering datasets. Our findings indicate that employing specific CoT prompts significantly enhances model performance compared to direct prompting, with the “Zhou” prompt yielding the highest average Krippendorff’s alpha score when used with GPT-4 (α = .83, 95% CI [.77, .90]; Table 4).</p>
<p>The superior performance of GPT-4 and GPT-3.5-turbo across most datasets (Table 6) underscores the advancements in reasoning capabilities of recent large language models. GPT-4, in particular, demonstrated substantial gains from externalized reasoning prompts, suggesting that more sophisticated models can better leverage CoT strategies to improve reasoning accuracy. For instance, GPT-4’s performance increased from a Krippendorff’s alpha of .71 (95% CI [.64, .79]) with direct prompting to .83 (95% CI [.77, .90]) with the “Zhou” prompt (Table 4).</p>
<p>The observation that FLAN-T5-XXL exhibited unexpectedly high performance on datasets such as CommonsenseQA (α = .81, 95% CI [.75, .85]; Table 7) suggests possible data contamination due to prior exposure during instruction fine-tuning. This raises concerns about the validity of its performance on these datasets and highlights the importance of ensuring dataset integrity in evaluating model capabilities.</p>
<p>Our results also reveal that different prompts vary in effectiveness depending on the dataset. The “Zhou” prompt excelled on OpenBookQA (α = .74, 95% CI [.66, .81]; Table 10), whereas the “Rephrase” prompt performed better on StrategyQA (α = .42, 95% CI [.30, .55]). This variability suggests that tailoring prompts to the specific reasoning demands of a task can enhance model performance. The effectiveness of the “Rephrase” prompt on StrategyQA may be attributed to its ability to help models disentangle ambiguous questions by encouraging initial rephrasing.</p>
<p>The self-critique prompt, which incorporated a reflection step, did not yield the expected performance improvements and sometimes produced multiple answers, complicating evaluation. This indicates that while self-critique is a promising strategy for enhancing reasoning, its implementation in zero-shot settings may require further refinement to be effective.</p>
<p>Our findings emphasize the potential of carefully designed zero-shot CoT prompts in enhancing the reasoning abilities of language models. The significant performance gains observed with certain prompts suggest that prompt engineering remains a critical factor in maximizing the utility of large language models for complex reasoning tasks.</p>
<p>However, the study has limitations that warrant consideration. The potential data contamination in FLAN-T5-XXL’s training data complicates the interpretation of its performance, particularly on datasets it may have been exposed to. Additionally, the lower performance on medical datasets like MedQA and MedMCQA (Table 5) highlights the challenges models face with specialized knowledge domains, suggesting a need for further research into domain-specific fine-tuning or prompting strategies.</p>
<p>Future work should focus on mitigating data contamination issues by utilizing cleaner datasets and exploring methods to detect and control for prior exposure. Furthermore, investigating the effectiveness of prompting strategies across a broader range of tasks and domains can provide deeper insights into the generalizability of CoT reasoning approaches.</p>
<p>In conclusion, this study demonstrates that zero-shot CoT prompting strategies can substantially improve the reasoning performance of large language models, particularly when aligned with the model’s capabilities and the task’s requirements. As language models continue to advance, leveraging sophisticated prompting techniques will be essential for unlocking their full potential in complex reasoning and decision-making tasks.</p>
</section>
<section id="good-but-still-lots-of-text" class="slide level2">
<h2>Good, but still lots of text</h2>
<ul>
<li>Possible strategy, but too much text to check</li>
<li>Lot’s of correction work for you</li>
</ul>
<div class="fragment">
<h3 id="rightarrow-refinement"><span class="math inline">\(\rightarrow\)</span> Refinement</h3>
<p>Let’s have the output in bullet points, structured in the main parts of a discussion.</p>
<p><small> <strong>Prompt:</strong> Please list the key points of your text as single-sentence bullet points, organized into the following parts of the discussion:</small></p><small>
<ul>
<li>Conclusion</li>
<li>Limitations</li>
<li>Related Work</li>
<li>Future Work</li>
</ul>
</small><p><small>Return it as a markdown file, so I can easily copy it. </small></p>
</div>
</section>
<section id="looks-good" class="slide level2 smaller" style="font-size: 0.5em;">
<h2>Looks good</h2>
<p>Conclusion</p>
<pre><code>•   Employing specific zero-shot chain-of-thought (CoT) prompts significantly enhances the performance of large language models compared to direct prompting.
•   The “Zhou” prompt yielded the highest average Krippendorff’s alpha score with GPT-4 (α = .83, 95% CI [.77, .90]), indicating its effectiveness in improving reasoning performance.
•   GPT-4 and GPT-3.5-turbo demonstrated superior performance across most datasets, highlighting advancements in recent large language models’ reasoning capabilities.
•   Tailoring prompts to the specific reasoning demands of a task can enhance model performance, as different prompts vary in effectiveness depending on the dataset.
•   Carefully designed zero-shot CoT prompts can substantially improve the reasoning abilities of language models, emphasizing the importance of prompt engineering.</code></pre>
<p>Limitations</p>
<pre><code>•   Potential data contamination in FLAN-T5-XXL’s training data complicates the interpretation of its performance on certain datasets.
•   Lower performance on medical datasets like MedQA and MedMCQA highlights challenges models face with specialized knowledge domains.
•   The self-critique prompt did not yield expected performance improvements and sometimes produced multiple answers, complicating evaluation.
•   Findings may be limited by the specific models and datasets used, necessitating caution in generalizing the results.</code></pre>
<p>Related Work</p>
<pre><code>•   Builds upon previous zero-shot CoT prompting strategies by Kojima et al. (2022) and Zhou et al. (2023b).
•   Relates to research on self-critique strategies in language models by Madaan et al. (2023) and Saunders et al. (2022).
•   Aligns with ongoing exploration of prompt engineering as a critical factor in enhancing language model performance.</code></pre>
<p>Future Work</p>
<pre><code>•   Focus on mitigating data contamination issues by utilizing cleaner datasets and developing methods to detect and control for prior exposure.
•   Investigate the effectiveness of prompting strategies across a broader range of tasks and domains to assess generalizability.
•   Refine self-critique strategies in zero-shot settings to enhance their effectiveness in improving reasoning.
•   Explore domain-specific fine-tuning or prompting strategies to address challenges in specialized knowledge domains.</code></pre>
</section>
<section id="correct-formatting" class="slide level2">
<h2>Correct formatting</h2>
<h3 id="only-a-small-formatting-mistake-markdown-output-does-not-work-well-in-o1">Only a small formatting mistake: Markdown output does not work well in o1</h3>
<p>If you really want to have it as markdown use GPT-4. Tip: just change the model and continue within the chat.</p>
<p><strong>Prompt:</strong> Convert this text to markdown format.</p>

<img data-src="images/markdown_output.png" class="r-stretch"></section>
<section id="if-you-want-to-compare-to-the-original" class="slide level2 smaller" style="font-size: 0.5em;">
<h2>If you want to compare to the original</h2>
<p><strong>You can convert the original discussion from the paper turned into bullet points by o1-preview</strong></p>
<p><strong>Prompt:</strong></p>
<p>Read the scientific paper I am giving to you. List the key points only of the section discussion as single-sentence bullet points, organized into the following parts of the discussion. Provide only the most important 3-5 bullet points per section:</p>
<ul>
<li>Conclusion</li>
<li>Limitations</li>
<li>Related Work</li>
<li>Future Work</li>
</ul>
<p>Respond in plain text formatted as markdown.</p>
<p>Here is the finished paper including the discussion section:</p>
<p>““”</p>
<p>[full paper]</p>
<p>““”</p>
</section>
<section id="original-discussion-converted-to-bullet-points" class="slide level2 smaller" style="font-size: 0.4em;">
<h2>Original discussion converted to bullet points</h2>
<p><strong>Conclusion</strong></p>
<ul>
<li>Using reasoning strategies significantly improves performance beyond direct prompting alone.</li>
<li>The improvement does not strongly correlate with model size; both large (GPT-4) and smaller (Command XL) models benefit from reasoning strategies.</li>
<li>State-of-the-art prompts developed by Zhou and Kojima demonstrate robust performance across various scenarios.</li>
<li>GPT-4 consistently outperforms other models across all datasets tested.</li>
<li>Krippendorff’s alpha is a practical and intuitive metric for evaluating performance on multiple-choice datasets.</li>
</ul>
<p><strong>Limitations</strong></p>
<ul>
<li>The study used subsampled datasets due to budget constraints, limiting direct comparison to full benchmark tests.</li>
<li>Some benchmark datasets had quality issues, with questions not allowing a single best answer, affecting model evaluation.</li>
<li>Use of closed-source models that change over time makes replication and comparison difficult.</li>
<li>Potential data contamination and leakage due to lack of model documentation complicates result interpretation across models.</li>
</ul>
<p><strong>Related Work</strong></p>
<ul>
<li>Previous studies have evaluated zero-shot prompting performance, including Liévin et al.&nbsp;(2022) on medical datasets.</li>
<li>Earlier work includes evaluating models on commonsense data (Zhou et al., 2020) and assessing T0’s performance on multiple-choice tasks (Orlanski, 2022).</li>
<li>Zero-shot reasoning can be enhanced through precise reasoning steps and logic dependencies (Ling et al., 2024; Zhao et al., 2023).</li>
<li>This study contributes by focusing on simple and versatile chain-of-thought prompting approaches across various models.</li>
</ul>
<p><strong>Future Work</strong></p>
<ul>
<li>Extend the study by evaluating prompts and datasets with additional models, particularly openly available LLMs like LLaMa, Pythia, Alpaca, StableLM, and OpenAssistant.</li>
<li>Conduct user evaluations of the quality and explanatory utility of reasoning chains generated by different prompts and models.</li>
<li>Future research could compare semantically similar prompts through paraphrasing to understand their impact on performance.</li>
</ul>
</section>
<section id="test-how-it-is-doing-by-comparing" class="slide level2">
<h2>Test how it is doing by comparing</h2>
<p><br> <br></p>
<p><strong>Do a side by side view to check if it captures the main points</strong></p>
<div class="fragment">
<p><br> <br></p>
<h3 id="in-real-life-it-probably-needs-refinement">In real life it probably needs refinement</h3>
<p>In a paper where you need to write the discussion, you can just copy the suggested discussion in bullet point format into a Google docs and work on it.</p>
</div>
</section>
<section id="tip-worflow-with-google-docs" class="slide level2 smaller">
<h2>Tip: worflow with Google docs</h2>
<p><strong>This only works in Chrome:</strong></p>
<p><img data-src="images/google_docs.png"> Paste text from Markdown</p>
<p>Easy exchange of formatted text between Google docs and Chatbot interface.</p>
<ul>
<li>Thinking about text &amp; argument flow</li>
<li>Update bullet points</li>
</ul>
<p><br> Current developments: ChatGPT already includes the option to continue working on outputs manually.</p>
<ul>
<li>GPT-4o with Canvas (in Beta, only for GPT-4o)</li>
</ul>
</section>
<section id="can-the-model-write-a-discussion-from-your-bullet-points" class="slide level2">
<h2>Can the model write a discussion from your bullet points?</h2>
<p>Give the bullet points of the original discussion to the Chatbot and let it write</p>
</section>
<section id="preparation-setting-the-right-tone" class="slide level2">
<h2>Preparation: Setting the right tone</h2>
<ul>
<li><p>o1: First model that writes good scientific text without specific prompting</p></li>
<li><p>For scientific writing other models are often not precise and concise enough.</p></li>
<li><p>Guide them to have a specific writing style by giving an instruction or example texts.</p></li>
<li><p>Prompt GPT-4/GPT-4o (free access) with your paper up to discussion, the bullet points and the writing style instruction on the next slide.</p></li>
</ul>
</section>
<section id="writing-style-instructions" class="slide level2 scrollable smaller">
<h2>Writing style instructions</h2>
<p>Example of an Writing Style Guide:</p>
<h3 id="structure-and-formatting">1. Structure and Formatting</h3>
<ul>
<li>Use simple, clear language focused on one main idea per sentence</li>
<li>Employ short paragraphs (2-4 sentences) to enhance readability</li>
<li>Begin with a concise, attention-grabbing title and subtitle</li>
<li>Use headings and subheadings to organize content logically</li>
<li>Incorporate formatting elements (e.g., bold text, italics) sparingly for emphasis</li>
<li>Use bullet points or numbered lists for key takeaways or steps</li>
</ul>
<h3 id="content-organization">2. Content Organization</h3>
<ul>
<li>Start with the most important information (inverted pyramid style)</li>
<li>Ensure each paragraph focuses on a single main idea</li>
<li>Organize content into clear sections, each building upon the previous one</li>
<li>Include occasional single-sentence paragraphs for impact</li>
</ul>
<h3 id="flow-and-engagement">3. Flow and Engagement</h3>
<ul>
<li>Open with a compelling hook to capture reader interest</li>
<li>Pose thought-provoking questions to involve the reader</li>
<li>Maintain a strong flow of ideas throughout the text</li>
<li>Use transitional phrases to connect ideas and paragraphs</li>
<li>Create and use strong “concept handles” (catchy phrases that sum up complex ideas)</li>
<li>Use analogies and metaphors sparingly to explain complex concepts</li>
<li>Incorporate relevant real or hypothetical scenarios to illustrate points</li>
</ul>
<h3 id="depth-and-conciseness">4. Depth and Conciseness</h3>
<ul>
<li>Provide depth on key points without becoming verbose</li>
<li>Break down complex ideas into digestible chunks</li>
<li>Use precise language to convey maximum information in minimal words</li>
<li>Begin with concrete examples before introducing abstract principles</li>
<li>Use multiple, diverse examples to illustrate complex points</li>
<li>Apply introduced ideas to real-world scenarios to demonstrate their relevance</li>
</ul>
<h3 id="persuasion-and-balance">5. Persuasion and Balance</h3>
<ul>
<li>Present a balanced view by acknowledging multiple perspectives</li>
<li>Address potential counterarguments proactively</li>
<li>Use appropriate language to connect with your target audience</li>
</ul>
<h3 id="technical-and-scientific-writing">6. Technical and Scientific Writing</h3>
<ul>
<li>Explain technical concepts in accessible language</li>
<li>Provide context for why the topic matters to the reader or the broader field</li>
</ul>
<h3 id="tone-and-voice">7. Tone and Voice</h3>
<ul>
<li>Employ active voice and direct language</li>
<li>Maintain a professional yet accessible tone</li>
<li>Avoid being overly academic or jargon-heavy</li>
<li>Use an engaging and slightly conversational style to create a sense of dialogue</li>
<li>Present ideas thoughtfully, showing respect for the reader’s intelligence</li>
<li>Convey complex ideas efficiently without sacrificing depth</li>
<li>Maintain a forward-looking and slightly enthusiastic tone, especially when discussing potential developments</li>
<li>Balance optimism about possibilities with acknowledgment of challenges</li>
<li>Aim to inform and engage without being pedantic or oversimplifying</li>
</ul>
</section>
<section id="take-aways-for-scientific-writing-with-llm-chatbots" class="slide level2">
<h2>Take aways for scientific writing with LLM Chatbots</h2>
<ol type="1">
<li>Let the Chatbot create a draft of parts of your paper in bullet points.</li>
<li>Refine the structure &amp; overview manually.</li>
<li>Then let the Chatbot write:
<ul>
<li>one paragraph</li>
<li>refine manually</li>
<li>provide existing paragraphs as context for the next</li>
</ul></li>
</ol>
</section>
<section id="writing-further-use-cases-for-academics" class="slide level2">
<h2>Writing: Further use cases for academics</h2>
<ul>
<li>Ideas where else you could use LLM chatbots to write?</li>
</ul>
<div class="fragment">
<ul>
<li>Revise, proof-read, summarise, shorten, finding titles, review</li>
<li>Refine your own writing
<ul>
<li>Useful as context/task examples: your texts before and after your supervisor feedback</li>
</ul></li>
<li>Tone/style checking</li>
<li>Getting feedback on specified aspects of drafts (<a href="https://www.clearerthinking.org/post/writing">Example</a>)</li>
<li>Providing your paper, the <a href="https://chatgpt.com/share/671669a4-77ac-800b-a49a-7d210914c464">reviewer requests</a> for rewriting, let it rephrase</li>
</ul>
<aside class="notes">
<p>Use examples from book of Tim Skern for scientific writing</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<!-- ## Different strategy: bullet points{.smaller style="font-size: 0.4em;"}
### Discussion

- **Overview of Study Findings:**
  - The study evaluated ten zero-shot chain-of-thought (CoT) prompting strategies across six language models on six datasets.
  - Specific CoT prompts significantly improved model performance over direct prompting, exemplified by the "Zhou" prompt showing the highest performance with GPT-4 (Krippendorff's alpha = .83, CI [.77, .90]).

- **Model Performance Insights:**
  - GPT-4 and GPT-3.5-turbo consistently outperformed other models, highlighting advancements in model reasoning capabilities.
  - GPT-4 particularly benefited from externalized reasoning prompts, demonstrating enhanced accuracy and reasoning depth.

- **Impact of Data Contamination:**
  - FLAN-T5-XXL's performance suggests potential data contamination, as it showed high scores on datasets it was fine-tuned on, raising validity concerns regarding its true capability.

- **Effectiveness of Prompt Strategies:**
  - Different prompts showed varying effectiveness across datasets, suggesting that prompt tailoring to task specifics can optimize performance.
  - "Zhou" prompt was most effective on OpenBookQA, while "Rephrase" excelled in clarifying ambiguous questions in StrategyQA.

- **Challenges with Self-Critique Prompts:**
  - The self-critique prompt did not perform as expected, indicating complexities in implementing reflection and critique in zero-shot settings.

- **Implications and Future Directions:**
  - The findings emphasize the importance of prompt engineering in enhancing reasoning with large language models.
  - Limitations noted include potential data contamination and lower performance in specialized domains like medicine, pointing to areas for future research.
  - Future work should explore cleaner datasets and methods to detect and correct prior model exposure, and test the scalability of prompting strategies across broader tasks.

- **Conclusion:**
  - This study demonstrates that zero-shot CoT prompting can significantly enhance the reasoning capabilities of large language models, with strategic prompt design playing a pivotal role.

## How are we doing this time?

- Looks pretty good...
- Additional improvement: 
  - Structure of a scientific discussion

  <br>

- If you get to many bullet points:
  - Let model select most important points for each section
  
. . .

### $\rightarrow$ Next (even smarter) try

Model input - to do ?????????????????????????

## Fit it into subheadings{.smaller style="font-size: 0.4em;"}

#### Conclusion
- **Enhanced Model Performance Through CoT Prompts:**
  - Ten zero-shot chain-of-thought (CoT) prompting strategies significantly improved performance across six language models compared to direct prompting.
  - The "Zhou" prompt notably enhanced GPT-4's performance, achieving the highest Krippendorff's alpha (α = .83, CI [.77, .90]).

- **Superior Performance of Advanced Models:**
  - GPT-4 and GPT-3.5-turbo outperformed other models in complex reasoning tasks, underscoring the advancements in AI capabilities.

#### Limitations
- **Data Contamination Concerns:**
  - FLAN-T5-XXL's unexpectedly high performance on familiar datasets suggests potential data contamination, complicating the assessment of its true reasoning capabilities.

- **Challenges in Medical Domains:**
  - The study revealed lower performance on specialized medical datasets, highlighting the difficulty models face in domains requiring extensive specialized knowledge.

#### Related Work
- **Prompt Efficacy Across Datasets:**
  - Different prompts exhibited variable effectiveness, with "Zhou" excelling on OpenBookQA and "Rephrase" better suited for disentangling StrategyQA's ambiguous queries.
  - This variability aligns with prior findings that tailored prompting can critically influence model performance (referenced studies and ongoing research in AI prompting).

#### Future Work
- **Addressing Data Contamination:**
  - Future studies should focus on cleaner datasets and developing methods to detect and prevent data contamination to ensure model evaluations are accurate and reflective of true capabilities.

- **Expanding Domain-Specific Research:**
  - Investigating more robust domain-specific prompting strategies, especially in medical fields, to enhance the precision and applicability of language models in specialized tasks.

- **Refining Self-Critique and Reflective Prompts:**
  - Further exploration is needed to optimize self-critique prompts, ensuring they effectively contribute to model reasoning without introducing complexities that hinder performance. -->
<div class="quarto-auto-generated-content">
<div class="footer footer-default">

</div>
</div>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="writing_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="writing_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="writing_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="writing_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="writing_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="writing_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="writing_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="writing_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="writing_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="writing_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>