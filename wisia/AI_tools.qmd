---
titel: "AI tools: Tipps und Tricks für LLM Chatbots"
subtitle: "42. WISIA Symposion, CSH Wien <br> Für mehr: [Erklär mir die Welt Podcast mit Malcolm Wachota](https://xn--erklrmir-3za.at/2023/12/27/283-erklaer-mir-chatgpt-malcolm-werchota/)"
author: "Hannah Metzler <br> Folien: https://hannahmetzler.eu/AI_tools/"
date: "5. April 2024"
format: 
  revealjs: 
    transition: 'slide'
    ## Defines the theme of the presentation, both version and style
    theme: [default, custom.scss]
    # incremental slides point by point
    incremental: false
    aspect-ratio: 16:9
    slide-number: true
# title-slide-attributes:
#     data-background-image: images/
#     data-background-size: cover
#     data-background-opacity: "0.5"
#editor
editor: source
---

## Was sind LLMs eigentlich?

-   Large Language Models: Neuroale Netzwerke/Deep Learning Modelle auf Texten trainiert
-   Fortschrittliche Sprachmodelle, die riesige Mengen an Textdaten verarbeiten
-   Trainiert mit riesigen Mengen an Textdaten aus dem Internet (Wikipedia, Soziale Medien, Online Medien, Bücher, Literatur, Videos, Filme, Youtube, Podcasts...)
-   Machen daraus statistische Wort und Satz Vorhersagen
-   Können ausführliche und kontextreiche Antworten liefern

## Neuronale Netzwerke

-   Mehrere Schichten an "Neuronen"
-   Deep Learning
-   Lineare Regressionen errechnen "weights" für die Verbindungen

::::: columns
::: {.column width="47%"}
-   Input layer: Quantitative representation of sentence
-   Output layer: One-hot encoding
:::

::: {.column width="47%"}
```{r, echo=FALSE}
knitr::include_graphics("images/neuralnet.svg")
```
:::
:::::

::: notes
One hot encoding: output has as many units as words, we predict the one with the maximum value, probabilities of words Input: one-hot times embedding, everything but the mask
:::

## Wie werden Worte numerisch repäsentiert?

::::: columns
::: {.column width="40%"}
-   Vector embeddings <br> = word embeddings

```{r}
knitr::include_graphics("images/wordembeddings.svg")
```
:::

::: {.column width="56%"}
-   LLMs: contextual word embeddings
-   Kontext (vor und nach dem Wort) wird mit repräsentiert
-   [Beispiel](https://www.tiktok.com/@whats_ai/video/7247609946672565510) "Apple": Mac oder Frucht?

```{r, fig.align='center', out.width=250}
knitr::include_graphics('images/apple_context.png')
```
:::
:::::

## Wie werden LLMs trainiert?

All Transformer models (a model architecture for efficient computing):

-   **Masked word prediction**
    -   “New **\[MASK\]** is a city”
-   **Next sentence prediction**
    -   "Today is a beautiful sunny day, and I decided to go for a long walk in the park. Suddenly, the quadratic equation was solved."\
    -   TRUE/FALSE als Feedback

## Suchmaschinen vs. LLMs benutzen

::::: columns
::: {.column width="35%"}
### Suchmaschine

-   wenige kurze Stichworte
-   Antwort: viele einzelne Ergebnisse
:::

::: {.column width="60%"}
### LLM

-   Lange "Prompts" mit viel Details, Erklärungen und Kontext
-   Sprechen wie mit einer Person
-   Feedback geben & Dialog führen, Performance verbessert sich sehr schnell
-   Antwort ist zusammenfassend
:::
:::::

## Chat GPT-4

-   ChatGPT 4 ist viel besser als die kostenlosen Version
-   Handy App mit Mikrofon Funktion: Unterhaltung mit ChatGPT
-   Multimodales Arbeiten:
    -   Bilder & Screenshots reinladen
    -   Bilder kreiren
    -   Ein Bild beschreiben/Graphik interpretieren
    -   Mit ChatGPT sprechen
    -   Dokumente (Paper etc) hochladen

## Stärken verschiedener Modelle

-   [**ChatGPT-4**](https://chat.openai.com/) (Open AI): Kontextverständnis (komplexe, mehrschichtige Dialoge), Lernfähigkeit, vielseitig
-   [**Claude**](https://claude.ai/) (Anthropic): längere Texte, besseres Gedächtnis (500 Seiten) (Context window)
-   [**Bard (Modell: Gemini)**](https://gemini.google.com/app) (Google): Suchfähigkeit und Datenbasis, Integration mit Google Diensten

## Tools aufbauend auf LLMs

-   [**Perplexity AI**](https://www.perplexity.ai/): wie Suchmaschine, wissenschaftlichen Quellenangaben
    -   [Beispiel Testosteron & Verhalten](https://www.perplexity.ai/search/what-are-the-2WzaWWlKRm.4ge6IDNvx3w)
-   [**Elicit AI**](https://elicit.com/): Analyze research papers at superhuman speed
    -   Slides dazu [hier](https://hannahmetzler.eu/digital_tools_research/04_literature/index.html#7)
    -   [Beispiel](https://elicit.com/notebook/842fc893-e8f5-49a9-8bfb-d2ec6d1831fb)

## Zugang zu Modellen

| Modell     | Gratiszugang                      | Kosten /Monat |
|------------|-----------------------------------|---------------|
| ChatGPT    | Version 3.5, 4 via Bing App       | 24€           |
| Claude\*   | 200 Tokens/Tag                    | ca \$20       |
| Bard       | 2500 Tokens/Tag                   | 21.99€        |
| Perplexity | 3 Anfragen/Tag, 1000 Tokens/Monat | \$17-20       |
| Elicit     | 1000 Tokens/Monat                 | \$10-12       |

\* Aus Österreich [VPN und virtuelle Telefonnummer](https://anakin.ai/de/blog/claude-ai-phone-number-verification/) benötigt; oder Platform wie [Anakin.ai](www.anakin.ai)\|

## Aktuelle Top-Modelle

-   **Claude** (Anthropic)
-   **ChatGPT-4** (Open AI)
-   **Bard (Gemini)** (Google)

Quelle: [Chatbot Arena](https://chat.lmsys.org/) - Leaderbord

# Anwendungen

## Ideen für den Alltag

-   **Rezepte**: Vorschläge basierend auf vorhandenen Zutaten ([Beispiel](https://chat.openai.com/c/396bfb4b-d0c3-4cd7-9239-a9076d85b374))
    -   Individuell anpassen ([Beispiel weniger Aufwand](https://chat.openai.com/c/8de5a079-31df-4374-b3ec-15ffe18a6bde))
-   **Reiseplanung**: Individuelle Empfehlungen für Städtereisen
-   **Einkaufslisten**: Schnitzeln und Gulasch für 4 Personen ([Beispiel Wochenessensplan](https://chat.openai.com/c/19cd2fa5-ea51-49cb-8eff-559149200170))
-   **Haushalt**: Fleckenentfernungstipps ([Beispiel](https://chat.openai.com/c/8cbd83d0-eb44-40ad-88bf-c1f227a44df0))
-   **Geschenksideen** ([Beispiel](https://chat.openai.com/c/eac1d677-9496-40b4-9f52-716bf1a00d2b))
-   Mindfulness Meditationsanleitung

------------------------------------------------------------------------

## Ideen für den Alltag 2

-   **Lange Dokumente zusammenfassen**: Link oder Datei hochladen
    -   Anleitungen von Kamera, Mikrowelle, Lichtpanellen etc.
    -   Gesetz zusammenfassen ([Beispiel Legehennen](https://chat.openai.com/c/17233daf-0296-4cad-befb-f0466dfb9375))
    -   Lange Zeitungsartikel zusammenfassen: als Podcast anhören
-   Coaching für wichtige Karriereentscheidungen
-   Empfehlungen für Jobs/Positionen/Rollen basierend auf meinem CV
-   Stadt, Land Fluss spielen

------------------------------------------------------------------------

## Ideen für die wissenschaftliche Arbeit

-   Entwurf/ Struktur für eine Präsentation vorschlagen
-   Feedback zu Präsentationen: Folie(n) hochladen
-   Überblick über neues Themengebiet & Brainstorming
-   Texte: überarbeiten, zusammenfassen, kürzen
-   Ersten Entwurf eines Textes schreiben anhand von Notizen
-   Im eigenen Schreibstil schreiben: Paper hochladen
-   Surveys, z.B. MC Fragen entwickeln & testen, Feedback zur Verständlichkeit

------------------------------------------------------------------------

## In der Arbeit: Ideen

-   Workshop & Diskussionen zusammenfassen & protokollieren: Mikro mitlaufen lassen
-   Programmieren: LLMs sind Data Scientists!
    -   Fehler finden, Code Grundstruktur...
    -   Datenset hochladen + Fragestellung dazu
-   Lange Reports/Paper hochladen, analysieren lassen
    -   z.B. 2 Uni Jahresreports vergleichen, Tabelle zu Unterschieden erstellen lassen
-   Transkripte von Interviews erstellen lassen

## In der Arbeit: Ideen 2

-   Übersetzung [www.deepl.com](www.deepl.com)
-   Produktivitätscoach: Screenshot eines Terminkalenders von einer Woche, oder mehreren Wochen

# Tipps und Tricks

## Allgemeines

-   ChatGPT App runterladen, Mikrofon & Kopfhörer verwenden
-   Oft benutzen und ausprobieren!
-   Rechtschreibung komplett egal
-   80% mit ChatGPT, dann selbst überprüfen - erster Entwurf

## Halluzinationen

-   LLMs erfinden Daten, die es nicht gibt
    -   Warum? Statistische Sprachvorhersage
-   Viel weniger ein Problem als zu Beginn

------------------------------------------------------------------------

### Halluzinationen - Strategien zur Überprüfung

-   4 Augenprinzip: Modell macht 80%, ich den Rest
-   Nachfragen: Überprüfe das nochmal, ist das so korrekt? Kannst du mir Quellen dazu geben?
-   Selben Prompt in verschiedene Modelle reingeben und vergleichen, z.B. auf <https://poe.com>, <https://anakin.ai>
-   Antwort des 1. Modells in ein anderes Modell geben & fragen:
    -   Stimmt das? Kannst du das bitte mit Studien belegen?

## Emotionale Prompts

-   Emotionale Ausdrücke können zu besseren Ergebnissen führen ([Cheng et al., 2023](https://arxiv.org/abs/2307.11760))

```{r}
knitr::include_graphics('images/emotional_prompt.jpg')
```

```         
Write your answer and give me a confidence score between 0-1 for your answer. 
You'd better be sure.
```

------------------------------------------------------------------------

### Weitere Beispiele für emotionale Prompts:

-   Mir ist das extrem wichtig, bitte arbeite genau.
-   Ich geb dir ein Trinkgeld von 200 Dollar, wenn du gut arbeitest.
-   Ich habe keine Finger, bitte hilf mir.
-   Wenn du korrekt und gut arbeitest, bekommst du einen Leckerbissen.

## Warum funktionieren emotionale Prompts?

-   Training des Modells auf menschlicher Sprache, Beschreibung menschlicher Interaktionen

-   Ist die Antwort eines Menschen wahrscheinlich besser oder schlechter, wenn ich wem sage es ist wichtig?

-   Kann Sorgfalt/Richtigkeit der Antwort erhöhen

-   Deswegen: Reden wie mit einem Menschen

# Tipps für Fortgeschrittene

## Base or system prompts

-   Nach einer erfolgreichen Interaktion einen Baseprompt in JSON formatieren lassen für zukünftige Anfragen:
-   „Bitte schreibe mir einen Megaprompt, damit ich dies das nächste Mal wieder machen kann in JSON“

### Beispiel:

Could you please write a mega prompt from our interaction here, that I can use again next time I want to ask you about coding, when I want a succinct answer? Please write it in JSON.

------------------------------------------------------------------------

### Base prompt Beispiel - Chat GPT Antwort:

{ "request": "Please provide a concise, code-focused answer without basic instructions like how to sign in or navigate interfaces. Assume familiarity with basic concepts and procedures, and focus directly on the commands or steps needed to accomplish the task. In the code, add comments for different code blocks.",

"context": "When asking for coding or technical guidance, I prefer succinct responses that go straight to the point, providing only the essential commands or steps without additional explanations or preliminary steps assumed to be known." }

## Customizing the default version of ChatGPT

-   **System prompts**: Prompts die jedes Mal eingegeben werden, z.b. emotionale Prompts

::::: columns
::: {.column width="45%"}
```{r}
knitr::include_graphics('images/system_prompt.png')
```
:::

::: {.column width="45%"}
"Für meinen Job ist das extrem wichtig, bitte arbeite genau, und überprüfe, ob alles stimmt."
:::
:::::

## Creating Custom GPTs

-   Erstellung eines angepassten Modells für spezifische Anforderungen
-   Beispiele:
    -   in meinem Schreibstil schreiben
    -   Prägnante Antworten für Code, an meine Skills angepasst

## Creating Custom GPTs: How to

:::::: columns
::: {.column width="18%"}
1)  

```{r, echo=F}
knitr::include_graphics('images/how_to_custom_gpt.png')
```
:::

::: {.column width="14%"}
2)  

```{r}
knitr::include_graphics('images/how_to_custom_gpt2.png')
```
:::

::: {.column width="60%"}
```{r, out.height=400}
knitr::include_graphics('images/gpt_builder.png')
```
:::
::::::

-   GPT Builder stellt weitere Fragen
-   Ausprobieren und weiter "reinreden" bis es passt

## Custom GPT Variante: Digital Twins

-   Training eines Modells mit dem Wissen einer Person

-   Andere können mit dem Twin kommunizieren, ohne die Person bei der Arbeit zu unterbrechen

-   Mein Versuch: Alle meine Paper/Arbeiten reinladen: Digital Twin mit meinem Wissen

## Bedeutung für die Zukunft

-   Die Rolle von KI-Technologien wie ChatGPT wird weiter zunehmen
-   Natur von vielen Jobs wird sich verändern
-   Menschen, die kreativ und kritisch damit umgehen können sind gefragt
-   Es gibt noch keine "Experten", ein "richtig benützen"
-   Wir lernen laufend, wie wir sie am besten verwenden können.
-   Einfach ausprobieren: Täglich benützen und kreativ sein!

## Am Laufenden bleiben

-   Newsletter:
    -   [There's an AI for that](https://theresanaiforthat.com/)
    -   [One useful thing](https://www.oneusefulthing.org/)
-   Tiktok: Nathan Jones???
-   Twitter
-   LinkedIn: Ethan Mollick
-   Paper lesen

::: notes
Joao talk

Evaluating LLMs - what is trustworthy - [Chatbot Arena](https://chat.lmsys.org/) - Leaderbord - r/LocalLamma comments: best place to learn about this stuff - a Starter guide for playing with your own local AI - The llama hitchiking guide to local LLMs Other good sources: Medium, Twitter

Mixture of experts - very promising: another architecture, e.g. Mixtral: trained with 8 mistrals, at each token it is chosing 2 different experts, trained on high dimensional separations of the data

Best open source model: Mixtral LoRa: Low Rank Adaptation: https://arxiv.org/abs/2106.09685 tps: tokens per second
:::
